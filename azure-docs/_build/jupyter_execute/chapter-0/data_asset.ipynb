{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data asset\n",
    "\n",
    "A data asset in Azure Machine Learning refers to a reusable piece of data that can be used across various parts of the Azure Machine Learning service. It essentially represents a dataset that has been registered in an Azure Machine Learning workspace. These data assets can include things like training data, test data, data used for feature extraction, etc.\n",
    "\n",
    "Some key features about a data asset:\n",
    "\n",
    "`Reusable`: Once registered, these datasets can be used in multiple experiments, pipelines, or training processes without the need to reload or redefine them each time.\n",
    "\n",
    "`Version Control`: Azure ML allows you to version your data assets. This means you can keep track of changes over time, experiment with different versions of the same dataset, and ensure reproducibility in your machine learning workflows.\n",
    "\n",
    "`Scalability`: Data assets in Azure ML are designed to handle large-scale datasets efficiently, leveraging Azure's cloud infrastructure.\n",
    "\n",
    "`Integration`: These data assets can be easily integrated with Azure ML components and pipelines.\n",
    "\n",
    "`Security and Governance`: Azure ML provides features to secure your data assets, including encryption, role-based access control, and monitoring.\n",
    "\n",
    "By using data assets, one can streamline their workflows in Azure ML, ensuring efficient, reproducible, and scalable machine learning processes.\n",
    "\n",
    "## Creating a data asset in Azure ML\n",
    "\n",
    "Usually, data assets originate from azure blob storage. Thus, a typical workflow is the following: \n",
    "\n",
    "![data asset workflow](./images/data_asset.png)\n",
    "\n",
    "First, an observable phenomena's data gets stored in azure blob storage. Then, the data is registered as a data asset in Azure ML. Each new data in a data asset has a unique version.\n",
    "\n",
    "Now any further component/pipeline can use a specific data asset version as input. \n",
    "\n",
    "## Creating a data asset using Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure ml datasets\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Data, AzureBlobDatastore, AccountKeyConfiguration\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Exceptions\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "def create_dataset_from_storage(\n",
    "    ml_client: MLClient,\n",
    "    datastore_name: str,\n",
    "    container_name: str,\n",
    "    account_key: str,\n",
    "    storage_account_name: str,\n",
    "    dataset_name: str,\n",
    "    folder_name: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Description\n",
    "    -----------\n",
    "    A function to create a data asset from Azure Blob Storage to Azure ML workspace\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    :param ml_client: MLClient object\n",
    "    :param datastore_name: Azure ML Datastore name\n",
    "    :param container_name: Azure Blob Storage container name\n",
    "    :param account_key: Azure Blob Storage account_key (primary/secondary storage key)\n",
    "    :param storage_account_name: Azure Storage Account name\n",
    "    :param dataset_name: Azure ML Dataset name; This will the name for the data asset\n",
    "    \"\"\"\n",
    "\n",
    "    # Checking if datastore exists\n",
    "    try:\n",
    "        datastore = ml_client.datastores.get(datastore_name)\n",
    "        print(f\"Azure ML Datastore {datastore_name} already exists\")\n",
    "    except ResourceNotFoundError:\n",
    "        datastore = None\n",
    "        print(f\"Creating new Azure ML Datastore: {datastore_name}\")\n",
    "    # If not create datastores\n",
    "    if not datastore:\n",
    "        datastore = AzureBlobDatastore(\n",
    "            name=datastore_name,\n",
    "            description=\"Datastore pointing to a blob container using https protocol.\",\n",
    "            account_name=storage_account_name,\n",
    "            container_name=container_name,\n",
    "            protocol=\"https\",\n",
    "            credentials=AccountKeyConfiguration(account_key=account_key),\n",
    "        )\n",
    "        ml_client.create_or_update(datastore)\n",
    "        print(f\"Azure ML Datastore {datastore_name} created\")\n",
    "\n",
    "    # Define path to datastore\n",
    "    path = f\"azureml://datastores/{datastore.name}/paths/{folder_name}\"\n",
    "\n",
    "    # Define the dataset object\n",
    "    waste_types_data = Data(\n",
    "        path=path,\n",
    "        type=AssetTypes.URI_FOLDER,\n",
    "        description=\"testing azure.ai.ml\",\n",
    "        name=dataset_name,\n",
    "    )\n",
    "    print(\"Creating Azure ML dataset\")\n",
    "    \n",
    "    # Create the dataset in the workspace\n",
    "    data_info = ml_client.data.create_or_update(waste_types_data)\n",
    "    print(\n",
    "        f\"Azure ML dataset {dataset_name} created. Dataset version is {data_info.version}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now imagine we have data called \"data.parquet\" in the azure blob storage container \"electricity\" in the folder \"2024-01-25\".\n",
    "We can create a data asset from this data using the following code:\n",
    "```python\n",
    "ml_client = MLClient()\n",
    "create_dataset_from_storage(\n",
    "    ml_client=ml_client,\n",
    "    datastore_name=\"electricity\",\n",
    "    container_name=\"data.parquet\",\n",
    "    account_key=\"account_key\",\n",
    "    storage_account_name=\"storage_account_name\",\n",
    "    dataset_name=\"data.parquet\",\n",
    "    folder_name=\"2024-01-25\",\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}